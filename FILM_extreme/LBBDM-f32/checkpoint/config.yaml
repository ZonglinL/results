!!python/object:argparse.Namespace
args: !!python/object:argparse.Namespace
  config: configs/Template-LBBDM-video.yaml
  gpu_ids: '0'
  max_epoch: null
  max_steps: null
  port: '12355'
  result_path: results
  resume_model: results/VQGAN/vimeo_unet.pth
  resume_optim: null
  sample_at_start: false
  sample_to_eval: true
  save_top: false
  seed: 1234
  train: false
data: !!python/object:argparse.Namespace
  dataset_config: !!python/object:argparse.Namespace
    aug_cut: false
    aug_noise: false
    cat: false
    channels: 3
    dataset_path: /vast/zl3958/data
    eval: FILM
    flip: true
    image_size: 256
    mode: extreme
    to_normal: true
  dataset_name: FILM_extreme
  dataset_type: Interpolation
  test: !!python/object:argparse.Namespace
    batch_size: 1
  train: !!python/object:argparse.Namespace
    batch_size: 32
    shuffle: true
  val: !!python/object:argparse.Namespace
    batch_size: 32
    shuffle: false
model: !!python/object:argparse.Namespace
  BB: !!python/object:argparse.Namespace
    lr_scheduler: !!python/object:argparse.Namespace
      cooldown: 3000
      factor: 0.5
      min_lr: 5.0e-07
      patience: 3000
      threshold: 0.0001
    optimizer: !!python/object:argparse.Namespace
      beta1: 0.9
      lr: 0.0001
      optimizer: Adam
      weight_decay: 0.0
    params: !!python/object:argparse.Namespace
      UNetParams: !!python/object:argparse.Namespace
        attention_resolutions: !!python/tuple
        - 8
        - 4
        - 2
        channel_mult: !!python/tuple
        - 1
        - 2
        - 4
        condition_key: first_stage
        context_dim: null
        conv_resample: true
        dims: 3
        dropout: 0
        image_size: 8
        in_channels: 6
        model_channels: 128
        num_heads: 1
        num_res_blocks: 2
        out_channels: 3
        resblock_updown: true
        use_max_self_attn: false
        use_scale_shift_norm: true
      eta: 1.0
      loss_type: l1
      max_var: 1.0
      mt_type: linear
      num_timesteps: 1000
      objective: grad
      sample_step: 10
      sample_type: linear
      skip_sample: true
  CondStageParams: !!python/object:argparse.Namespace
    in_channels: 3
    n_stages: 4
    out_channels: 3
  EMA: !!python/object:argparse.Namespace
    ema_decay: 0.995
    start_ema_step: 3000
    update_ema_interval: 8
    use_ema: true
  VQGAN: !!python/object:argparse.Namespace
    cond_stage_config: __is_first_stage__
    params: !!python/object:argparse.Namespace
      ckpt_path: results/VQGAN/vimeo_new.ckpt
      ddconfig: !!python/object:argparse.Namespace
        attn_resolutions:
        - 16
        attn_type: max
        ch: 64
        ch_mult:
        - 1
        - 2
        - 2
        - 2
        - 4
        cond_type: max_cross_attn
        double_z: false
        dropout: 0.0
        in_channels: 3
        load_VFI: null
        num_head_channels: -1
        num_res_blocks: 1
        out_ch: 3
        resolution: 256
        z_channels: 3
      embed_dim: 3
      lossconfig: !!python/object:argparse.Namespace
        target: torch.nn.Identity
      n_embed: 8192
  latent_before_quant_conv: false
  model_load_path: results/VQGAN/vimeo_unet.pth
  model_name: LBBDM-f32
  model_type: LBBDM
  normalize_latent: false
  only_load_latent_mean_std: false
result: !!python/object:argparse.Namespace
  ckpt_path: results/FILM_extreme/LBBDM-f32/checkpoint
  image_path: results/FILM_extreme/LBBDM-f32/image
  log_path: results/FILM_extreme/LBBDM-f32/log
  sample_path: results/FILM_extreme/LBBDM-f32/samples
  sample_to_eval_path: results/FILM_extreme/LBBDM-f32/sample_to_eval
runner: BBDMRunner
testing: !!python/object:argparse.Namespace
  clip_denoised: false
  sample_num: 1
training: !!python/object:argparse.Namespace
  accumulate_grad_batches: 1
  device:
  - !!python/object/apply:torch.device
    - cuda
    - 0
  n_epochs: 400
  n_steps: 1000000
  sample_interval: 1
  save_interval: 1
  use_DDP: false
  validation_interval: 1
